# 条件概率与独立性

---

## 一、条件概率

$有随机试验E 及事件A，B，若P(B)>0，则称$

$$P(A|B)=\frac{P(AB)}{P(B)}$$

$为 A 在B 发生的条件下的条件概率.$

### 注

- $P(A|B)是将样本空间\Omega 压缩成B后计算概率$
- $当B取样本空间\Omega 时，P(A|B)就是无条件概率P(A)$
- $条件概率确实是概率$

## 二、全概率公式

$设A1，A2，...，An为Ω的一个划分且P(A_i)>0，i=1,2,n，$

$则对于任意的B \sub \Omega，有$

$$P(B)= \sum_{i=1}^nP(B|A_i)P(A_i)$$

### 证明

$$P(B)=P(B\Omega)=P(B\sum_{i=1}^nA_i)=P(\sum_{i=1}^nBA_i)$$

$$=\sum_{i=1}^n P(BA_i)=\sum_{i=1}^nP(A_i)P(B|A)$$

全概率公式的意义在于当A的构成较复杂时，可通过对引入某种合适的划
分

在这种划分下可将A分解为一系列局部的较为简单的事件，在计算出这些局部的事件的概率后

$再通过全概率公式求出P(A)$

## 三、贝叶斯公式

我怕们通常见到诸如这样的广告：购买某产品，它将会给你带来某效用；或听到这样的承诺：投资某产品或投资某地，你的回报率将是多少。

但如果人们问一个反问题：我要求回报率达到多少，应投资何产品或在何地投资呢？或者我要求达到某效用应购买何产品呢？

显然这样的反问题是很有意义的.

下面介绍的贝叶斯公式就是这类问题在概率中的相应模型.

$设A_1，A_2，...，An 为样本空间的一个划分$

$且P(A_i)>0, i =1,2 ，... ，n ，对任意随机事件B \subset Ω ，当 P (B )> 0时 ，则有$

$$P(A_i|B)=\frac{P(B|A)P(A_i)}{\sum_{k=1}^nP(B|A)P(A_k)}$$

$一般称P(A_i)为先验概率,P(A_i|B )为后验概率.$

## 四、独立性

某国在1000年前的某月某日在某地区下了一场雨，那么这场雨对1000年后该地区的某月某日的气象不可能造成什么影响

这样的问题就抽象出事件的独立性的概念

### 1. 定义

$设事件A，B满足$

$$P(AB)=P(A)P(B)$$

$则称A与B独立.$

$由定义可知，当 A 与B独立时，B与A也独立，故称之为A与B相互独立，简称A与B独立 .$

### 2. 独立的传递性

$对于n个事件A_1,A_2……,A_n,若同时满足$

$$P(A_{i_1}A_{i_2} ...A_{i_k})=P(A_{i_1} )P(A_{i_2} )……P(A_{i_k} )(2≤k≤n)， $$

$则称A_1，A_2，...，A_n 相互独立.$

### 3. 性质

- $设 P (B ) > 0 ， 则 A 与 B 相 互 独 立 的 充 要 条 件 为 P (A | B ) = P (A)$
- $\{A，B\}，\{A，\overline{B}\}，\{\overline{A}，B\}，\{\overline{A}，\overline{B}\}四对事件中若有一对相互独立，则其余三对相互独立$
- $A,B,C,D相互独立\Rightarrow A\cup B, C\cup D相互独立$